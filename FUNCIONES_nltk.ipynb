{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. nltk.corpus.PlaintextCorpusReader\n",
    "\n",
    "Para qué sirve: Esta función permite leer archivos de texto plano y acceder a ellos como un corpus.\n",
    "\n",
    "Sintaxis: PlaintextCorpusReader(root, fileids, word_tokenizer=nltk.word_tokenize)\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "corpus_root = '/ruta/a/los/archivos/txt'\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. nltk.tokenize.sent_tokenize\n",
    "\n",
    "Para qué sirve: Divide un texto en oraciones utilizando un algoritmo de tokenización de oraciones.\n",
    "\n",
    "Sintaxis: sent_tokenize(text)\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"Este es un ejemplo de texto. ¡Espero que te sea útil!\"\n",
    "sentences = sent_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. nltk.tokenize.word_tokenize\n",
    "\n",
    "Para qué sirve: Divide un texto en palabras utilizando un algoritmo de tokenización de palabras.\n",
    "\n",
    "Sintaxis: word_tokenize(text)\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Este es un ejemplo de texto.\"\n",
    "words = word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. nltk.corpus.gutenberg\n",
    "\n",
    "Para qué sirve: Ofrece acceso al corpus de textos de Project Gutenberg.\n",
    "\n",
    "Sintaxis: nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "Ejemplo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "file_ids = gutenberg.fileids()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. nltk.corpus.WebText\n",
    "\n",
    "Para qué sirve: Proporciona acceso al corpus de textos web, que contiene mensajes de chats y foros.\n",
    "\n",
    "Sintaxis: nltk.corpus.webtext.fileids()\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext\n",
    "\n",
    "file_ids = webtext.fileids()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. nltk.corpus.treebank\n",
    "\n",
    "Para qué sirve: Ofrece acceso al corpus de Treebank, que contiene textos etiquetados con partes del discurso y árboles de sintaxis.\n",
    "\n",
    "Sintaxis: nltk.corpus.treebank.fileids()\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "\n",
    "file_ids = treebank.fileids()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. nltk.corpus.ConllCorpusReader\n",
    "\n",
    "Para qué sirve: Lee archivos en formato CoNLL (formato tabular utilizado en el procesamiento del lenguaje natural) y los convierte en corpus.\n",
    "\n",
    "Sintaxis: ConllCorpusReader(root, file_pattern, columntypes, separator='\\t')\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import ConllCorpusReader\n",
    "\n",
    "corpus_root = '/ruta/a/los/archivos/conll'\n",
    "conll_reader = ConllCorpusReader(corpus_root, '.*\\.conll', columntypes=('words', 'pos'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. nltk.corpus.BracketParseCorpusReader\n",
    "\n",
    "Para qué sirve: Lee archivos en formato de árboles de sintaxis bracketed y los convierte en corpus.\n",
    "\n",
    "Sintaxis: BracketParseCorpusReader(root, file_pattern)\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import BracketParseCorpusReader\n",
    "\n",
    "corpus_root = '/ruta/a/los/archivos/parse'\n",
    "parse_reader = BracketParseCorpusReader(corpus_root, '.*\\.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. nltk.corpus.XMLCorpusReader\n",
    "\n",
    "Para qué sirve: Lee archivos XML y los convierte en corpus.\n",
    "\n",
    "Sintaxis: XMLCorpusReader(root, fileids, wrap_etree=False)\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import XMLCorpusReader\n",
    "\n",
    "corpus_root = '/ruta/a/los/archivos/xml'\n",
    "xml_reader = XMLCorpusReader(corpus_root, '.*\\.xml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. nltk.corpus.CategorizedPlaintextCorpusReader\n",
    "\n",
    "Para qué sirve: Lee archivos de texto y los organiza en categorías.\n",
    "\n",
    "Sintaxis: CategorizedPlaintextCorpusReader(root, fileids, cat_pattern, encoding='utf8')\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import CategorizedPlaintextCorpusReader\n",
    "\n",
    "corpus_root = '/ruta/a/los/archivos/categorizados'\n",
    "reader = CategorizedPlaintextCorpusReader(corpus_root, r'(?!\\.).*\\.txt', cat_pattern=r'(neg|pos)/.*')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. nltk.probability.FreqDist\n",
    "\n",
    "Para qué sirve: Calcula la frecuencia de cada elemento en una lista.\n",
    "\n",
    "Sintaxis: FreqDist(tokens)\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "tokens = ['apple', 'banana', 'apple', 'orange', 'banana']\n",
    "freq_dist = FreqDist(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. nltk.collocations.BigramCollocationFinder\n",
    "\n",
    "Para qué sirve: Encuentra las colocaciones de bigramas en un texto.\n",
    "\n",
    "Sintaxis: BigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "tokens = ['this', 'is', 'a', 'test', 'sentence']\n",
    "bigram_finder = BigramCollocationFinder.from_words(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. nltk.translate.bleu_score.corpus_bleu\n",
    "\n",
    "Para qué sirve: Calcula el puntaje BLEU para una traducción automática en un corpus.\n",
    "\n",
    "Sintaxis: corpus_bleu(list_of_references, hypotheses)\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "references = [['this', 'is', 'a', 'test'], ['another', 'example']]\n",
    "hypotheses = [['this', 'is', 'a', 'test'], ['example', 'of', 'another']]\n",
    "score = corpus_bleu(references, hypotheses)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
